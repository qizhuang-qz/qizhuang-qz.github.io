<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="icon" type="image/x-icon" href="images/qizhuang.png" />
<title>Zhuang Qi (é½å£®)</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Zhuang Qi (é½å£®) </h1>
</div>
<table class="imgtable"><tr>
<!-- ç¬¬ä¸€åˆ— -->
<td><a href="https://qizhuang-qz.github.io/"><img src="images/qizhuang.png" alt="alt text" width="135px" /></a>&nbsp;</td>
<!-- ç¬¬äºŒåˆ— -->
<td align="left">
<p>æˆ‘ç›®å‰åœ¨<a href="https://www.sdu.edu.cn/">å±±ä¸œå¤§å­¦</a><a href="https://www.sc.sdu.edu.cn/">è½¯ä»¶å­¦é™¢</a>æ”»è¯»åšå£«å­¦ä½ï¼Œå¸ˆä»<a href="https://ercdm.sdu.edu.cn/info/1013/1523.htm"><b>å­Ÿé›·æ•™æˆ</b></a>ã€‚æœ¬äººå·²äº2022å¹´6æœˆä»æ±•å¤´å¤§å­¦å·¥å­¦é™¢è®¡ç®—æœºç³»è·å¾—å·¥ç¨‹ç¡•å£«å­¦ä½ï¼›äº2019å¹´6æœˆåœ¨æ²³åŒ—ç§‘æŠ€å¤§å­¦ç†å­¦é™¢ï¼Œä¿¡æ¯ä¸è®¡ç®—ç§‘å­¦ä¸“ä¸šè·å¾—äº†ç†å­¦å­¦å£«å­¦ä½ã€‚åœ¨å­¦æœŸé—´ï¼Œå›´ç»•äº’è”ç½‘å¤§æ•°æ®é©±åŠ¨ä¸‹çš„å¤šåª’ä½“è®¡ç®—å’Œæ•°æ®æŒ–æ˜ç­‰ç§‘å­¦é—®é¢˜å¼€å±•ç ”ç©¶ï¼Œä¸»è¦å†…å®¹åŒ…æ‹¬ç¦»ç¾¤å€¼æ£€æµ‹ç®—æ³•ç ”ç©¶ä»¥åŠå¤šæºä¿¡æ¯èåˆçš„è”é‚¦å­¦ä¹ ç®—æ³•ç ”ç©¶ã€‚ç›¸å…³æˆæœå·²åœ¨ACM MMã€ECCVã€ICMEã€TNNLSã€IDAJç­‰å›½å†…å¤–æƒå¨ä¼šè®®å’ŒæœŸåˆŠä¸­å‘è¡¨ã€‚æ­¤å¤–ï¼Œæˆ‘å°†äº2024å¹´12æœˆä»¥è”åˆåŸ¹å…»åšå£«ç”Ÿèº«ä»½å‰å¾€æ–°åŠ å¡å—æ´‹ç†å·¥å¤§å­¦è®¡ç®—ä¸æ•°æ®ç§‘å­¦å­¦é™¢<a href="https://www.sc.sdu.edu.cn/"><b>Han Yuæ•™æˆå›¢é˜Ÿ</b></a>äº¤æµå­¦ä¹ ã€‚</p>
<p>æˆ‘çš„ç ”ç©¶å…´è¶£ä¸»è¦åŒ…æ‹¬ğŸ˜ğŸ˜ğŸ˜: <br />
âœ”ï¸ <b>è”é‚¦å­¦ä¹  (Federated Learning)</b><br />
âœ”ï¸ <b>åˆ†å¸ƒå¤–æ³›åŒ– (Out-of-Distribution Generalization) </b><br />  
âœ”ï¸ <b>å¼‚å¸¸å€¼æ£€æµ‹ (Outlier Detection) </b><br /> 
</td>
<!-- ç¬¬ä¸‰åˆ— -->
<td align="left" class="contact-info">
  <ul><li><a href="mailto:z_qi@mail.sdu.edu.cn">ğŸ“§  [E-mail]</a></li></ul>
  <ul><li><a href="https://scholar.google.com/citations?user=l7wxjVwAAAAJ&hl=zh-CN">ğŸ“ [Google Scholar]</a></li></ul>
  <ul><li><a href="https://github.com/qizhuang-qz">ğŸ“¥ [GitHub]</a></li></ul>
  <ul><li><a href="https://orcid.org/0000-0002-0656-2309">ğŸ†” [ORCID]</a></li></ul>
  <ul><li><a href="EnHome.html">ğŸ“‘ [English Page]</a></li></ul>
</td>
</tr></table>

<h2>æ•™è‚²ç»å†</h2> 
<ul>
<li><p>2024.12 ~ ç°åœ¨: æ–°åŠ å¡å—æ´‹ç†å·¥å¤§å­¦, è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢, è®¿é—®åšå£« (CSC) [å¯¼å¸ˆ: ğŸ’â€â™‚ï¸<a href="https://personal.ntu.edu.sg/han.yu/">Han Yuæ•™æˆ</a>ğŸ‘] </p></li>
<li><p>2022.09 ~ ç°åœ¨: å±±ä¸œå¤§å­¦, è½¯ä»¶å­¦é™¢, åœ¨è¯»åšå£« [å¯¼å¸ˆ: ğŸ’â€â™‚ï¸<a href="https://ercdm.sdu.edu.cn/info/1013/1523.htm">å­Ÿé›·æ•™æˆ</a>ğŸ‘]</p></li>
<li><p>2019.09 ~ 2022.07: æ±•å¤´å¤§å­¦, å·¥å­¦é™¢è®¡ç®—æœºç³», ç¡•å£« </p></li>
<li><p>2015.09 ~ 2019.07: æ²³åŒ—ç§‘æŠ€å¤§å­¦, ç†å­¦é™¢, å­¦å£« </p></li>
</ul>

<h2>å­¦æœ¯è®ºæ–‡(*è¡¨ç¤ºé€šè®¯ä½œè€…)</h2>
  <h4>2024</h4>
    <ul><li><p><a href="https://XXXXXXX">Improving Global Generalization and Local Personalization for Federated Learning</a> <br />
    Lei Meng, <b>Zhuang Qi*</b>, Lei Wu, Xiaoyu Du, Zhaochuan Li, Lizhen Cui, Xiangxu Meng <br />
    <i>IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS'24</b>), 2024. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢ä¸€åŒº]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/29113">Attentive Modeling and Distillation for Out-of-Distribution Generalization of Federated Learning</a> <br />
    <b>Zhuang Qi</b>, Weihao He, Xiangxu Meng, Lei Meng <br />
    <i>IEEE International Conference on Multimedia and Expo (<b>ICME'24</b>), 2024. </i> <br /> 
    <span class="special">[CCF Bç±»ä¼šè®®, å½•ç”¨ç‡çº¦23.75%]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/FedCSL(2024).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/FedCSL">[Code]</a><a href="pdf/FedCSL-app.pdf">[Appendix]</a>
    </p></li></ul>
  
    <ul><li><p><a href="https://www.sciencedirect.com/science/article/pii/S0957417423023333">Cross-modal learning using privileged information for long-tailed image classification</a> <br />
    Xiangxian Li, Yuze Zheng, Haokai Ma, <b>Zhuang Qi</b>, Xiangxu Meng, Lei Meng <br />
    <i>Computational Visual Media (<b>CVM'24</b>), 2024. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢äºŒåŒº, CCF Cç±»æœŸåˆŠ]</span> </a>
    </p></li></ul>
  
    <ul><li><p><a href="https://ieeexplore.ieee.org/abstract/document/10098143">Robust Visual Tracking via Iterative Gradient Descent and Threshold Selectiong</a> <br />
    <b>Zhuang Qi</b>, Junlin Zhang, Xin Qi <br /> 
    <i>Arxiv, 2024. </i> <br />
    </p></li></ul>
  
    <ul><li><p><a href="https://ieeexplore.ieee.org/abstract/document/10149428">Cross-Training with Multi-View Knowledge Fusion for Heterogenous Federated Learning</a> <br />
    <b>Zhuang Qi</b>, Lei Meng, Weihao He, Ruohan Zhang, Yu Wang, Xin Qi, Xiangxu Meng <br />
    <i>Arxiv, 2024. </i> <br /> 
    </p></li></ul>
      
    <ul><li><p><a href="https://dl.acm.org/doi/abs/10.1145/3604809">Relation Modeling and Distillation for Learning with Noisy Labels</a> <br />
    Xiaming Chen, Junlin Zhang, <b>Zhuang Qi*</b>, Xin Qi* <br />
    <i>Arxiv, 2024. </i> <br /> 
    </p></li></ul>
    
    <ul><li><p><a href="https://link.springer.com/article/10.1007/s10489-023-04999-2">Comparative Study of Neighbor-based Methods for Local Outlier Detection</a> <br />
    <b>Zhuang Qi</b>, Junlin Zhang, Xiaming Chen, Xin Qi <br />
    <i>Arxiv, 2024. </i> <br /> 
    </p></li></ul>
    
    <ul><li><p><a href="https://ieeexplore.ieee.org/abstract/document/10310027">Machine Learning Empowering Drug Discovery: Applications, Opportunities and Challenges</a> <br /> 
    Xin Qi, Yuanchun Zhao, <b>Zhuang Qi</b>, Siyu Hou, Jiajia Chen <br />
    <i>Molecules, 2024. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢äºŒåŒº]</span> </a>
    </p></li></ul>

    <ul><li><p><a href="https://ieeexplore.ieee.org/abstract/document/10310027">åŸºäºè·¨æ¨¡æ€ç‰¹æƒä¿¡æ¯å¢å¼ºçš„å›¾åƒåˆ†ç±»æ–¹æ³•</a> <br /> 
    æè±¡è´¤ï¼Œ éƒ‘è£•æ³½ï¼Œ é©¬æµ©å‡¯ï¼Œ <b>é½å£®</b>ï¼Œ é—«æ™“ç¡•ï¼Œ å­Ÿç¥¥æ—­ï¼Œ å­Ÿé›· <br />
    <i>è½¯ä»¶å­¦æŠ¥, 2024. </i> <br /> 
    <span class="special">[CCF Aç±»ä¸­æ–‡æœŸåˆŠ]</span> </a>
    </p></li></ul>

  <h4>2023</h4>
    <ul><li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/29113">Class-aware convolution and attentive aggregation for image classification</a> <br />
    Zitan Chen, <b>Zhuang Qi</b>, Xiangxian Li, Yuqing Wang, Lei Meng, Xiangxu Meng <br />
    <i>Proceedings of the 5th ACM International Conference on Multimedia in Asia (<b>MM Asia'23</b>), 2023. </i> <br /> 
    <span class="special">[CCF Cç±»ä¼šè®®, å½•ç”¨ç‡çº¦23.75%]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/FedCSL(2024).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/FedCSL">[Code]</a><a href="pdf/FedCSL-app.pdf">[Appendix]</a>
    </p></li></ul>

    <ul><li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/29113">Class-level Structural Relation Modeling and Smoothing for Visual Representation Learning</a> <br />
    Zitan Chen, <b>Zhuang Qi</b>, Xiao Cao, Xiangxian Li, Xiangxu Meng, Lei Meng <br />
    <i>Proceedings of the 31st ACM International Conference on Multimedia (<b>MM'23</b>), 2023. </i> <br /> 
    <span class="special">[CCF Cç±»ä¼šè®®, å½•ç”¨ç‡çº¦23.75%]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/FedCSL(2024).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/FedCSL">[Code]</a><a href="pdf/FedCSL-app.pdf">[Appendix]</a>
    </p></li></ul>

    <ul><li><p><a href="https://dl.acm.org/doi/abs/10.1145/3511808.3557249">Cross-silo prototypical calibration for federated learning with non-iid data</a> <br />
    <b>Zhuang Qi</b>, Lei Meng, Zitan Chen, Han Hu, Hui Lin, Xiangxu Meng <br />
    <i>Proceedings of the 31st ACM International Conference on Multimedia (<b>MM'23</b>), 2023. </i> <br />
    <span class="special">[CCF Aç±»ä¼šè®®, å½•ç”¨ç‡çº¦21.6%]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/BCSL(2022).pdf">[PDF]</a>
    </p></li></ul>
  
    <ul><li><p><a href="https://ieeexplore.ieee.org/abstract/document/9791080">Unsupervised Segmentation of Haze Regions as Hard Attention for Haze Classification</a> <br />
    Jingyu Li, Haokai Ma, Xiangxian Li, <b>Zhuang Qi</b>, Xiangxu Meng, Lei Meng <br />
    <i>International Conference on Image and Graphics (<b>ICIG'23</b>), 2023. </i> <br /> 
    <span class="special">[EIä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/DCMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/DCMB">[Code]</a><a href="pdf/DCMB-supp.pdf">[Supplementary Material]</a>
    </p></li></ul>
   
    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Learning to fuse residual and conditional information for video compression and reconstruction</a> <br />
    Ran Wang, <b>Zhuang Qi</b>, Xiangxu Meng, Lei Meng <br />
    <i>International Conference on Image and Graphics (<b>ICIG'23</b>), 2023. </i> <br /> 
    <span class="special">[EIä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>
  
    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Cross-Training with Prototypical Distillation for improving the generalization of Federated Learning</a> <br />
    Tianhan Liu, <b>Zhuang Qi</b>, Zitan Chen, Xiangxu Meng, Lei Meng <br />
    <i>2023 IEEE International Conference on Multimedia and Expo (<b>ICME'23</b>), 2023. </i> <br /> 
    <span class="special">[CCF Bç±»ä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>

    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Cross-modal content inference and feature enrichment for cold-start recommendation</a> <br />
    Haokai Ma, <b>Zhuang Qi</b>, Xinxin Dong, Xiangxian Li, Yuze Zheng, Xiangxu Meng, Lei Meng <br />
    <i>2023 International Joint Conference on Neural Networks (<b>IJCNN'23</b>), 2023. </i> <br /> 
    <span class="special">[CCF Cç±»ä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>

    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Multi-channel attentive weighting of visual frames for multimodal video classification</a> <br />
    Yuqing Wang, <b>Zhuang Qi</b>, Xiangxian Li, Jinxing Liu, Xiangxu Meng, Lei Meng <br />
    <i>2023 International Joint Conference on Neural Networks (<b>IJCNN'23</b>), 2023. </i> <br /> 
    <span class="special">[CCF Cç±»ä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>

  <h4>2022</h4>
    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Meta-causal feature learning for out-of-distribution generalization</a> <br />
    Yuqing Wang, Xiangxian Li, <b>Zhuang Qi</b>, Jingyu Li, Xuelong Li, Xiangxu Meng, Lei Meng <br />
    <i>European Conference on Computer Vision (<b>ECCV'22</b>), 2022. </i> <br /> 
    <span class="special">[CCF Bç±»ä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>

    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Causal inference with sample balancing for out-of-distribution detection in visual classification</a> <br />
    Yuqing Wang, Xiangxian Li, Haokai Ma, <b>Zhuang Qi</b>, Xiangxu Meng, Lei Meng <br />
    <i>CAAI International Conference on Artificial Intelligence (<b>CICAI'22</b>), 2022. </i> <br /> 
    <span class="special">[CAAI Aç±»ä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>

    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Clustering-based curriculum construction for sample-balanced federated learning</a> <br />
    <b>Zhuang Qi</b>, Yuqing Wang, Zitan Chen, Ran Wang, Xiangxu Meng, Lei Meng <br />
    <i>CAAI International Conference on Artificial Intelligence (<b>CICAI'22</b>), 2022. </i> <br /> 
    <span class="special">[CAAI Aç±»ä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>

    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Prompt learning with cross-modal feature alignment for visual domain adaptation</a> <br />
    Jinxing Liu, Junjin Xiao, Haokai Ma, Xiangxian Li, <b>Zhuang Qi</b>, Xiangxu Meng, Lei Meng <br />
    <i>CAAI International Conference on Artificial Intelligence (<b>CICAI'22</b>), 2022. </i> <br /> 
    <span class="special">[CAAI Aç±»ä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>

    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">Unsupervised contrastive masking for visual haze classification</a> <br />
    Jingyu Li, Haokai Ma, Xiangxian Li, <b>Zhuang Qi</b>, Lei Meng, Xiangxu Meng <br />
    <i>Proceedings of the 2022 International Conference on Multimedia Retrieval (<b>ICMR'22</b>), 2022. </i> <br /> 
    <span class="special">[CCF Bç±»ä¼šè®®]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>

    <ul><li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521013402">A novel density-based outlier detection method using key attributes</a> <br />
    <b>Zhuang Qi</b>, Xiaming Chen <br />
    <i>Intelligent Data Analysis Journal (<b>IDA'22</b>), 2022. </i> <br /> 
    <span class="special">[CCF Cç±»æœŸåˆŠ]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/EAMB(2022).pdf">[PDF]</a><a href="https://github.com/Xianjie-Guo/EAMB">[Code]</a>
    </p></li></ul>
  
  <h4>2021</h4>
    <ul><li><p><a href="https://ieeexplore.ieee.org/abstract/document/9667769">Iterative gradient descent for outlier detection</a> <br />
    <b>Zhuang Qi</b>, Dazhi Jiang, Xiaming Chen <br />
    <i>International Journal of Wavelets, Multiresolution and Information Processing (<b>IJWMIP'21</b>), 2021. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢å››åŒº]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/CTPC-frameworks(2021).pdf">[PDF]</a>
    </p></li></ul>

  <h4>2020</h4>
    <ul><li><p><a href="https://dl.acm.org/doi/abs/10.1145/3409382">Hdiht: a high-accuracy distributed iterative hard thresholding algorithm for compressed sensing</a> <br />
    Xiaming Chen, <b>Zhuang Qi</b>, Jianlong Xu <br />
    <i>IEEE Access, 2020. </i> <br /> 
    <span class="special">[ä¸­ç§‘é™¢äºŒåŒº]</span> ç›¸å…³ä¸‹è½½é“¾æ¥: <a href="pdf/CausalFS(2020).pdf">[PDF]</a><a href="https://github.com/kuiy/CausalFS">[Code]</a><a href="pdf/CausalFS-supp.pdf">[Supplementary Material]</a>
    </p></li></ul>

<h2>è£èª‰å¥–åŠ±</h2>
<ul>
<li><p>æ²³åŒ—ç§‘æŠ€å¤§å­¦2016-2017å­¦å¹´åº¦æ ¡çº§æ¨¡èŒƒå­¦ç”Ÿå¹²éƒ¨ (2017.11) </p></li>
<li><p>2017å¹´åº¦å›½å®¶åŠ±å¿—å¥–å­¦é‡‘ (2017.11) </p></li>
<li><p>æ²³åŒ—ç§‘æŠ€å¤§å­¦2016-2017å­¦å¹´åº¦æ ¡çº§ä¸‰ç­‰å¥–å­¦é‡‘ (2017.11) </p></li>
<li><p>2018å¹´æ²³åŒ—çœå¤§å­¦ç”Ÿæ•°å­¦ç«èµ›ä¸€ç­‰å¥– (2018.12) </p></li>
<li><p>2018å¹´å…¨å›½å¤§å­¦ç”Ÿæ•°å­¦ç«èµ›ä¸‰ç­‰å¥– (2018.12) </p></li>
<li><p>æ±•å¤´å¤§å­¦2021å¹´åº¦ç¡•å£«ç”Ÿä¸€ç­‰å­¦ä¸šå¥–å­¦é‡‘ (2021.12) </p></li>
<li><p>2021å¹´å…¨å›½é«˜ç­‰é™¢æ ¡æ•°å­¦èƒ½åŠ›æŒ‘æˆ˜èµ›å†³èµ›äºŒç­‰å¥– (2021.12) </p></li>
<li><p>2022å¹´é¦–å±ŠIPv6æŠ€æœ¯åº”ç”¨åˆ›æ–°å¤§èµ›ç§‘æ•™èµ›é“æš¨ç¬¬å…­å±Šä¸‹ä¸€ä»£äº’è”ç½‘æŠ€æœ¯åˆ›æ–°å¤§èµ›ä¸­è·å¾—å†³èµ›ä¼˜ç§€å¥– (2022.12)</p></li>
<li><p>ç¬¬åå››å±Šä¸­å›½å¤§å­¦ç”ŸæœåŠ¡å¤–åŒ…åˆ›æ–°åˆ›ä¸šå¤§èµ›â€œåˆåˆä¿¡æ¯æ¯â€åŒ—éƒ¨èµ›åŒºèµ›ï¼Œåˆ›æ–°å®è·µç±»ï¼ŒäºŒç­‰å¥– (2023.06)</p></li>
<li><p>ç¬¬åå››å±Šä¸­å›½å¤§å­¦ç”ŸæœåŠ¡å¤–åŒ…åˆ›æ–°åˆ›ä¸šå¤§èµ›ï¼Œåˆ›æ–°å®è·µç±»ï¼Œä¸‰ç­‰å¥– (2023.07)</p></li>
<li><p>ç¬¬å››å±ŠCCFå¤§å­¦ç”Ÿå­¦æœ¯ç§€ï¼Œåšå£«ç»„ï¼Œä¸‰ç­‰å¥– (2024.05)</p></li>
<li><p>2024å¹´å›½å®¶å…¬æ´¾ç•™å­¦èµ„æ ¼ï¼ˆCSCï¼‰ï¼Œè”åˆåŸ¹å…»åšå£«ç”Ÿ (2024.07)</p></li>
</ul>  

  
<h2>å‘æ˜ä¸“åˆ©</h2>
<ul>
<li><p>åŸºäºåŸå‹å¼•å¯¼äº¤å‰è®­ç»ƒæœºåˆ¶çš„è”é‚¦å­¦ä¹ ç³»ç»ŸåŠæ–¹æ³• <br />
å­Ÿé›·, <b>é½å£®</b>, åˆ˜å¤©æ¶µ, å­Ÿç¥¥æ—­<br />
å›½å®¶å‘æ˜ä¸“åˆ©, ç”³è¯·å·: 2023103105396, 2023.3.23.</p>

<li><p>åŸºäºè·¨æ¨¡æ€è¯­ä¹‰æ¨ç†å’Œèåˆçš„è§†è§‰æ„ŸçŸ¥æ¨èæ–¹æ³•åŠç³»ç»Ÿ <br />
å­Ÿé›·, é©¬æµ©å‡¯, <b>é½å£®</b>, æè±¡è´¤, éƒ‘è£•æ³½, å­Ÿç¥¥æ—­<br />
å›½å®¶å‘æ˜ä¸“åˆ©, æˆæƒå…¬å‘Šå·: CN 114936901 B, 2024.05.28.</p>
  
<li><p>åŸºäºè·¨æ¨¡æ€è¯­ä¹‰è¡¨å¾å­¦ä¹ å’Œèåˆçš„å›¾åƒåˆ†ç±»æ–¹æ³•åŠç³»ç»Ÿ <br />
å­Ÿé›·, æè±¡è´¤, éƒ‘è£•æ³½, é©¬æµ©å‡¯, <b>é½å£®</b>, å­Ÿç¥¥æ—­<br />
å›½å®¶å‘æ˜ä¸“åˆ©, æˆæƒå…¬å‘Šå·: CN 114898156 B, 2024.06.04.</p>
</ul>


<h2>è¯¾é¢˜é¡¹ç›®</h2>
<ul><li><p>é¢å‘éšç§ä¿æŠ¤æ•°æ®çš„è”é‚¦å› æœå…³ç³»æ¨æ–­ç®—æ³•ç ”ç©¶ (No.62376087), 2024.01-2027.12 <br />
<b>é¡¹ç›®éª¨å¹²</b>;  ç»è´¹:51ä¸‡å…ƒ <br />
å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›® <br /></p></li></ul>

<ul><li><p>è·¨åª’ä½“å› æœæ¨æ–­ä¸å¯ä¿¡æœºå™¨å­¦ä¹  (No. 2021ZD0111801), 2021.12-2025.11 <br />
<b>å­è¯¾é¢˜éª¨å¹²</b>;  ç»è´¹:180ä¸‡å…ƒ <br />
ç§‘æŠ€éƒ¨ç§‘æŠ€åˆ›æ–°2030-â€œæ–°ä¸€ä»£äººå·¥æ™ºèƒ½â€é‡å¤§é¡¹ç›® <br /></p></li></ul>

<ul><li><p>å¸¸è¯†çŸ¥è¯†å­¦ä¹ ä¸å› æœåˆ†æ (No. 2020AAA0106100), 2020.11-2024.10 <br />
<b>è¯¾é¢˜éª¨å¹²</b>;  ç»è´¹:180ä¸‡å…ƒ <br />
ç§‘æŠ€éƒ¨ç§‘æŠ€åˆ›æ–°2030-â€œæ–°ä¸€ä»£äººå·¥æ™ºèƒ½â€é‡å¤§é¡¹ç›® <br /></p></li></ul>


<h2>å­¦æœ¯æœåŠ¡</h2>
<h4>æœŸåˆŠå®¡ç¨¿</h4>
<ul>
<li><p>IEEE Transactions on Knowledge and Data Engineering </p></li>
<li><p>IEEE Transactions on Neural Networks and Learning Systems </p></li>
<li><p>ACM Transactions on Knowledge Discovery from Data </p></li>
<li><p>IEEE Transactions on Signal and Information Processing over Networks </p></li>
<li><p>IEEE Transactions on Emerging Topics in Computational Intelligence </p></li>
<li><p>Neurocomputing </p></li>
<li><p>Applied Intelligence </p></li>
<li><p>International Journal of Machine Learning and Cybernetics </p></li>
<li><p>The Journal of Supercomputing </p></li>
<li><p>Intelligent Automation and Soft Computing </p></li>
<li><p>CMC-Computers Materials & Continua </p></li>
<li><p>Neural Processing Letters </p></li>
</ul>

<h4>ä¼šè®®å®¡ç¨¿</h4>
<ul>
  <li><p>The International Workshop on Trustworthy Federated Learning in Conjunction with IJCAI 2023 (FL-IJCAI'23), PC Member </p></li>
  <li><p>The International Workshop on Federated Learning in the Age of Foundation Models (FL@FM-NeurIPS'23), PC Member </p></li>
  <li><p>Association for the Advancement of Artificial Intelligence (AAAI'24), PC Member </p></li>
  <li><p>The International Workshop on Federated Foundation Models for the Web 2024 (FL@FM-TheWebConf'24), PC Member </p></li>
  <li><p>International Joint Conference on Artificial Intelligence (IJCAI'24), PC Member </p></li>
  <li><p>The International Workshop on Federated Learning and Foundation Models (FL@FM-ICME'24), PC Member </p></li>
</ul>

<h2>ç½‘ç«™è®¿é—®ç»Ÿè®¡ (è‡ª2023å¹´12æœˆèµ·)</h2>
<a href="https://clustrmaps.com/site/1bxn1"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=4V6eYQ2IPE90W5uH_zCPr6SfzhrxmDDztM3gjnQ8ILE&cl=ffffff" /></a><br />
<!-- <br /><br /> -->
<!-- <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&pause=1000&color=119DF7&background=428FFF31&center=true&vCenter=true&random=false&width=435&lines=ç¥æ‚¨åœ¨å­¦æœ¯ç ”ç©¶çš„é“è·¯ä¸Šè¶Šèµ°è¶Šè¿œğŸ›«ğŸ›«ğŸ›«ï¼;ä¸æ–­å–å¾—æ–°çš„çªç ´å’Œæˆå°±ğŸ’ªğŸ’ªğŸ’ªï¼" alt="Typing SVG" /> -->


<div id="footer">
<div id="footer-text">
<br>Page generated 2024-06-30, by <a href="https://xianjie-guo.github.io/">Xianjie Guo</a>.
</div>
</div>
</div>
</body>
</html>
